{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors-in-variables estimation of specific climate sensitivity\n",
    "by D. Heslop (david.heslop@anu.edu.au), E.J. Rohling, G. L. Foster, & J. Yu, submitted.\n",
    "\n",
    "### Notebook 2 - Perform EIV regression\n",
    "Perform EIV regression using the time series created in Notebook 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages\n",
    "Package requirements are provided in the accompanying ```requirements.txt``` file.\n",
    "\n",
    "N.B., for this example notebook needs to be run twice, once for ```CO2_2ppm.txt``` and once for ```CO2_20ppm.txt```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the files containing the regression variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfile = 'CO2_20ppm.txt' #define the binned CO2 record with 2ppm uncertainties\n",
    "yfile = 'GMST_bin.txt' #define the binned GMST record file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the random number generator seed to ensure repeatability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 54321 #random number generator seed\n",
    "np.random.seed(seed_value) #set the random number generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the CO$_2$ radiative forcing effect \n",
    "\n",
    "A first-order approximation of the radiative forcing effect, $\\Delta R_{\\mathrm{[CO2]}}$, of CO$_2$ is (Myhre, 1998):\n",
    "\n",
    "\\begin{equation}\n",
    "f_{\\Delta R\\mathrm{[CO2]}}(\\mathrm{CO}_2) = 5.35 \\log(\\mathrm{CO}_2 / C_0),\n",
    "\\end{equation}\n",
    "\n",
    "where $C_0$ is a reference CO$_2$ concentration. Conversion of CO$_2$ into radiative forcing is defined in the ```DeltaF_CO2``` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeltaF_CO2(CO2,C0):\n",
    "    \n",
    "    ## INPUTS\n",
    "    # CO2 = CO2 concentration\n",
    "    # C0 = reference CO2 concentration\n",
    "\n",
    "    ## OUTPUT\n",
    "    # radiative forcing in W/m2\n",
    "    \n",
    "    return 5.35*np.log((CO2)/C0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define EIV objective function based on the negative log-likelihood (manuscript equ 23)\n",
    "In this case the negative log-likelihood is defined by two terms:\n",
    "\n",
    "```dy``` = Gaussian uncertainty on the GMST with an additional Gaussian scatter term\n",
    "\n",
    "```dx``` = Uncertainty on the radiative forcing defined by the distribution in Appendix A\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(X,x,y,dx,dy,C0,counts): #funtion to find negative log-likelihood\n",
    "    \n",
    "    ## INPUTS\n",
    "    # X = array containing [true CO2 values, sigma, gradient of fit, intercept of fit]\n",
    "    # x = observed CO2 values\n",
    "    # y = observed GMST values\n",
    "    # dx = standard deviation of CO2 uncertainty\n",
    "    # dy = standard deviation of GMST uncertainty\n",
    "    # C0 = reference CO2 concentration\n",
    "    # counts - how many times each point should be considered (used in bootstrapping)\n",
    "\n",
    "    ## OUTPUT\n",
    "    # negative log-likelihood of data given the model\n",
    "    \n",
    "    n = np.size(x) #number of data points\n",
    "    gamma = DeltaF_CO2(X[:n],C0) #estimated true CO2 values converted to radiative forcing\n",
    "    sigma = np.abs(X[n]) #standard deviation of scatter in y-variable\n",
    "    pp = X[n+1:] #polynomial fit\n",
    "    \n",
    "    mu = np.polyval(pp,gamma) #predictions of true y-values\n",
    "    tau = np.sqrt(sigma**2+dy**2) #combine y-errors with scatter defined by sigma\n",
    "    \n",
    "    #negative log-likelihood for y variable (assuming Gaussian)\n",
    "    term1 = 0.5*((y-mu)/tau)**2\n",
    "    term1 += np.log(tau*np.sqrt(2*np.pi))\n",
    "    \n",
    "    #negative log-likeihood for x variable (CO2 radiative forcing)\n",
    "    term2 = 0.5*((C0*np.exp(gamma/5.35)-x)/dx)**2\n",
    "    term2 += np.log(dx*np.sqrt(2*np.pi))\n",
    "    term2 -= np.abs(gamma/5.35+np.log(C0)-np.log(5.35))\n",
    "    \n",
    "    return np.sum((term1+term2)*counts) #negative log-likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EIV uncertainties are estimated via block bootstrapping (required because we are working with time series rather than independent data)\n",
    "\n",
    "Function selects a collection of blocks with length defined by Hall (1995, doi:10.2307/2337534).\n",
    "\n",
    "The function needs to be run for each bootstrap iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_bootstrap(n):\n",
    "    \n",
    "    ## INPUTS\n",
    "    # n = number of points in the time series\n",
    "    \n",
    "    ## OUTPUTS\n",
    "    # block_idx = indicies of all points selected by the bootstrap\n",
    "    # unique_values = unique indicies\n",
    "    # counts = number of times each of the unique indicies occurs within the bootstrap\n",
    "    \n",
    "    lb = int(np.ceil(n**(1/5))) #block length\n",
    "    Nb = int(np.floor(n/lb)) #number of blocks to include   \n",
    "\n",
    "    blocks = np.zeros((Nb,lb)) #preallocate array to store block indicies\n",
    "    blocks[:,0] = np.random.randint(low=0,high=n-1,size=Nb) #randomly choose starting point of each block\n",
    "    for i in range(1,lb): #loop to add subsequent points to each block\n",
    "        blocks[:,i] = blocks[:,i-1]+1\n",
    "    blocks = np.concatenate(np.mod(blocks,n)) #periodic boundaries to stay within record limits\n",
    "    unique_values, counts = np.unique(blocks, return_counts=True) #unique indicies and occurance counts\n",
    "\n",
    "    return blocks.astype(int), unique_values.astype(int), counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and define the variables needed for the regression (see file name definitions above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.loadtxt(xfile)[:,0] #x-variable bin means\n",
    "dx = np.loadtxt(xfile)[:,1] #x-variable bin standard deviations\n",
    "n = np.size(x) #number of bins to be considered\n",
    "C0 = x[0] #reference CO2 concentration\n",
    "\n",
    "y = np.loadtxt(yfile)[:,0] #y-variable bin means\n",
    "dy = np.loadtxt(yfile)[:,1] #y-variable bin standard deviations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform the block bootstrap for the EIV, OLSi, and OLSo approaches (this can take a little time) \n",
    "\n",
    "```OLSi``` = Ordinary least-squares regression including an intercept term\n",
    "\n",
    "```OLSo``` = Ordinary least-squares regression without an intercept term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running.....\n",
      "Completed iteration 50 of 1000\n",
      "Completed iteration 100 of 1000\n",
      "Completed iteration 150 of 1000\n",
      "Completed iteration 200 of 1000\n",
      "Completed iteration 250 of 1000\n",
      "Completed iteration 300 of 1000\n",
      "Completed iteration 350 of 1000\n",
      "Completed iteration 400 of 1000\n",
      "Completed iteration 450 of 1000\n",
      "Completed iteration 500 of 1000\n",
      "Completed iteration 550 of 1000\n",
      "Completed iteration 600 of 1000\n",
      "Completed iteration 650 of 1000\n",
      "Completed iteration 700 of 1000\n",
      "Completed iteration 750 of 1000\n",
      "Completed iteration 800 of 1000\n",
      "Completed iteration 850 of 1000\n",
      "Completed iteration 900 of 1000\n",
      "Completed iteration 950 of 1000\n",
      "Completed iteration 1000 of 1000\n"
     ]
    }
   ],
   "source": [
    "niter = 1000 # number of block boostrap iterations\n",
    "\n",
    "#Define some model parameters\n",
    "order = 1 #EIV fit is 1st order polynomial\n",
    "options={'maxiter': int(10000*n)} #minimization options\n",
    "sigma0 = 0.5 #initial estimate for sigma\n",
    "\n",
    "pp_EIV = np.zeros((niter,order+1)) #preallocate array for EIV regression coefficients\n",
    "pp_OLSi = np.zeros((niter,order+1)) #preallocate array for OLSi regression coefficients\n",
    "pp_OLSo = np.zeros((niter,order)) #preallocate array for OLSo regression coefficients\n",
    "\n",
    "D = np.transpose(np.vstack((DeltaF_CO2(x,C0),np.ones(np.size(x))))) #OLSi and OLSo regression design matrix\n",
    "\n",
    "i = 0 #set counter to track completed bootstrap iterations\n",
    "print(\"Running.....\")\n",
    "while i<niter:\n",
    "    blocks, idx, counts = block_bootstrap(n) #select bootstrap indicies\n",
    "    \n",
    "    #form EIV optimization initialization\n",
    "    ppy = np.polyfit(DeltaF_CO2(x[idx],C0),y[idx],1) # regress y on x\n",
    "    ppx = np.polyfit(y[idx],DeltaF_CO2(x[idx],C0),1) # regress x on y\n",
    "    y0 = np.polyval(ppy,DeltaF_CO2(x[idx],C0))\n",
    "    y1 = (DeltaF_CO2(x[idx],C0)-ppx[1])/ppx[0]\n",
    "    pp = np.polyfit(DeltaF_CO2(x[idx],C0),0.5*(y0+y1),1) #average of y on x and x on y regressions \n",
    "    \n",
    "    Xini = np.hstack((x[idx],sigma0,pp)) #form initialization array\n",
    "    Fbb = minimize(nll, Xini, args=(x[idx],y[idx],dx[idx],dy[idx],C0,counts),options=options) #minimize nll\n",
    "    pp_EIV[i,:] = Fbb.x[-order-1:] #record solution\n",
    "    \n",
    "    pp_OLSi[i,:] = np.dot(np.linalg.pinv(D[blocks,:]),y[blocks]) #perform OLSi regression\n",
    "    pp_OLSo[i] = np.dot(np.linalg.pinv(D[blocks,0:1]),y[blocks]) #perform OLSo regression\n",
    "    \n",
    "    \n",
    "    if Fbb.success: #only accept result if the minimize function converged\n",
    "        i += 1\n",
    "        if np.mod(i,50)==0:\n",
    "            print(\"Completed iteration \"+format(i)+\" of \"+format(niter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output the results in preperation for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if xfile == 'CO2_20ppm.txt':\n",
    "    np.savetxt(\"CO2_20ppm_OLSo.txt\",pp_OLSo) #save the OLSo regression coefficients\n",
    "    np.savetxt(\"CO2_20ppm_OLSi.txt\",pp_OLSi) #save the OLSi regression coefficients\n",
    "    np.savetxt(\"CO2_20ppm_EIV.txt\",pp_EIV) #save the EIV regression coefficients\n",
    "else:\n",
    "    np.savetxt(\"CO2_2ppm_OLSo.txt\",pp_OLSo) #save the OLSo regression coefficients\n",
    "    np.savetxt(\"CO2_2ppm_OLSi.txt\",pp_OLSi) #save the OLSi regression coefficients\n",
    "    np.savetxt(\"CO2_2ppm_EIV.txt\",pp_EIV) #save the EIV regression coefficients        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
